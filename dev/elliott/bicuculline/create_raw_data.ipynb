{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=7> Create Raw Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset with bicuculine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download raw datasets locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we download the raw datasets locally using the general command from the `data access` tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### view folders:\n",
    "# aws --endpoint https://s3.braingeneers.gi.ucsc.edu s3 ls s3://braingeneers/ephys/2022-11-02-e-Hc11.1-chip16753/\n",
    "### download metadata\n",
    "# cd /workspaces/human_hippocampus/data/ephys/2022-11-02-e-Hc11.1-chip16753/\n",
    "# aws --endpoint https://s3.braingeneers.gi.ucsc.edu s3 cp s3://braingeneers/ephys/2022-11-02-e-Hc11.1-chip16753/metadata.json .\n",
    "### download raw data\n",
    "# mkdir -p original/data\n",
    "# cd original/data\n",
    "# aws --endpoint https://s3.braingeneers.gi.ucsc.edu s3 cp s3://braingeneers/ephys/2022-11-02-e-Hc11.1-chip16753/original/data/hc11.1_plated-11.1_chip-16753_rec_11.2.22AM-immediate_D.raw.h5 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow data access tutorial on how to load data into python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import braingeneers\n",
    "from braingeneers import analysis\n",
    "import braingeneers.data.datasets_electrophysiology as ephys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "braingeneers.set_default_endpoint(\"/workspaces/human_hippocampus/data\")\n",
    "metadata = ephys.load_metadata(\"2022-11-02-e-Hc11.1-chip16753\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the metadata we see that experiment 2 is the bicucculine experiment (experiment D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment3\n",
      "[{'num_frames': 8368400, 'path': 'original/data/hc11.1_plated-11.1_chip-16753_rec_11.2.22AM-immediate.raw.h5'}]\n",
      "experiment1\n",
      "[{'num_frames': 5557600, 'path': 'original/data/hc11.1_plated-11.1_chip-16753_rec_11.2.22AM-immediate_stim.raw.h5'}]\n",
      "experiment5\n",
      "[{'num_frames': 3794400, 'path': 'original/data/hc11.1_plated-11.1_chip-16753_rec_11.2.22AM-immediate_stim-B.raw.h5'}]\n",
      "experiment4\n",
      "[{'num_frames': 9440800, 'path': 'original/data/hc11.1_plated-11.1_chip-16753_rec_11.2.22AM-immediate_stim-C.raw.h5'}]\n",
      "experiment2\n",
      "[{'num_frames': 11353000, 'path': 'original/data/hc11.1_plated-11.1_chip-16753_rec_11.2.22AM-immediate_D.raw.h5'}]\n",
      "experiment6\n",
      "[{'num_frames': 9698200, 'path': 'original/data/hc11.1_plated-11.1_chip-16753_rec_11.2.22AM-immediate_E.raw.h5'}]\n"
     ]
    }
   ],
   "source": [
    "#metadata[\"ephys_experiments\"].keys()\n",
    "for key,val in metadata[\"ephys_experiments\"].items():\n",
    "    print(key)\n",
    "    print(val[\"blocks\"])\n",
    "#in the metadata we see that experiment 2 is the bicucculine experiment (experiment D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in data from experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/braingeneers/data/datasets_electrophysiology.py:209: UserWarning: Metadata is missing the required voltage_scaling_factor attribute. Using default value of 1.0.\n",
      "  warnings.warn('Metadata is missing the required voltage_scaling_factor attribute. Using default value of 1.0.')\n"
     ]
    }
   ],
   "source": [
    "# load in data from experiment 2\n",
    "raw_data = ephys.load_data( metadata=metadata, experiment=\"experiment2\", offset=5*20000, length=10*20000, channels=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1028, 200000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of the data\n",
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded the data into python we have select a subset of time from the data for which we want to analyze. For our analysis we don't actually need to consider every 20000 datapoints per second. For this reason, we `downsample` this subset of the data, which means that we consider, say, every other datapoint. This cuts the size of the data in half. In actuallity we on take every 20th datapoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to downsample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample abd remove artifact\n",
    "def downsample(wav_lfp, dec=20, fs=20000.0):\n",
    "    wav_data = signal.decimate(wav_lfp, dec)\n",
    "    return fs/dec, wav_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimate = 20\n",
    "fs= 20000\n",
    "down_fs = fs/decimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_down = []  # the variable that will hold the downsambled data\n",
    "for i in range(len(raw_data)-4): # we run this loop for all code except the last 4 channels, because they are dummy data\n",
    "    data_down.append( downsample( raw_data[i, 0:(fs*20)], dec=decimate, fs=fs)[1]  ) # we select the first 20seconds of the data, and then downsample it\n",
    "data_down = np.array( data_down ) # we turn the data into an np.array for easier future analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 10000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of the data\n",
    "data_down.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataset. We save the data in the folder `ephys_raw` instead of ephys so that the data is available on Github.\n",
    "\n",
    "<font color=\"orange\">This line is commented out to make sure we don't accidently overwrite the previous saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open( '/workspaces/human_hippocampus/data/ephys_raw/2022-11-02-e-Hc11.1-chip16753/D_start5s_stop15s_fs1ms.pkl' , 'wb') as file:\n",
    "#    pickle.dump(data_down, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check that we can load the data correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 10000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('/workspaces/human_hippocampus/data/ephys_raw/2022-11-02-e-Hc11.1-chip16753/D_start5s_stop15s_fs1ms.pkl', 'rb')\n",
    "checkit = pickle.load(file)\n",
    "file.close()\n",
    "checkit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create  dataset without biccuculine <font color=\"red\"> - Not Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
