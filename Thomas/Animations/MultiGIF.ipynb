{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "895358ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "import scipy.ndimage as ndimage\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.lines import Line2D\n",
    "from PIL import Image\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import braingeneers\n",
    "import braingeneers.data.datasets_electrophysiology as ephys\n",
    "from braingeneers.analysis.analysis import SpikeData, read_phy_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "228aebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data(start, stop, dataset_number):\n",
    "    dataset_path = f\"/home/jovyan/work/Human_Hippocampus/data/ephys/2023-04-02-hc328_rec/derived/kilosort2/2023_04_02_hc328_{dataset_number}_curated.zip\"\n",
    "    \n",
    "    # Map dataset_number to the corresponding light_data file\n",
    "    light_data_files = {\n",
    "        0: \"20230402T140926-2023_04_02_hc328_0_opto_stim_log.csv\",\n",
    "        1: \"20230402T141431-2023_04_02_hc328_1_opto_stim_log.csv\",\n",
    "        2: \"20230402T142358-2023_04_02_hc328_2_opto_stim_log.csv\",\n",
    "        3: \"20230402T142533-2023_04_02_hc328_3_opto_stim_log.csv\",\n",
    "        4: \"20230402T142658-2023_04_02_hc328_4_opto_stim_log.csv\",\n",
    "        5: \"20230402T142907-2023_04_02_hc328_5_opto_stim_log.csv\",\n",
    "        6: \"20230402T144122-2023_04_02_hc328_6_opto_stim_log.csv\",\n",
    "        7: \"20230402T145210-2023_04_02_hc328_7_opto_stim_log.csv\"\n",
    "    }\n",
    "\n",
    "    # Check if the dataset_number is valid\n",
    "    if dataset_number not in light_data_files:\n",
    "        raise ValueError(\"Invalid dataset_number\")\n",
    "\n",
    "    # Get the corresponding light_data file\n",
    "    light_data_file = light_data_files[dataset_number]\n",
    "\n",
    "    # Construct the light_data_path\n",
    "    light_data_path = f\"/home/jovyan/work/Human_Hippocampus/data/opto/hc328_20230402T14/{light_data_file}\"\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    light_data = pd.read_csv(light_data_path)\n",
    "\n",
    "\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    light_data = pd.read_csv(light_data_path)\n",
    "\n",
    "    # Rename the \"time (sec)\" column\n",
    "    light_data = light_data.rename(columns={\"time (sec)\": \"time change (sec)\"})\n",
    "    \n",
    "    # Calculate the time change values by subtracting the first value from each subsequent value\n",
    "    light_data[\"time change (sec)\"] = light_data[\"time change (sec)\"] - light_data.at[0, \"time change (sec)\"]\n",
    "\n",
    "    # Modify the values in the \"time change (sec)\" column based on the dataset number\n",
    "    if dataset_number == 5:\n",
    "        light_data[\"time change (sec)\"] = light_data[\"time change (sec)\"] + 10\n",
    "    elif dataset_number == 6:\n",
    "        light_data[\"time change (sec)\"] = light_data[\"time change (sec)\"] + 1\n",
    "\n",
    "    # Rename the \"on_duration (frames)\" column\n",
    "    light_data = light_data.rename(columns={\"on_duration (frames)\": \"on_duration (seconds)\"})\n",
    "\n",
    "    # Divide the values in the \"on_duration (seconds)\" column by 20000\n",
    "    light_data[\"on_duration (seconds)\"] = light_data[\"on_duration (seconds)\"] / 20000\n",
    "\n",
    "    # Rename the \"off_duration (frames)\" column\n",
    "    light_data = light_data.rename(columns={\"off_duration (frames)\": \"off_duration (seconds)\"})\n",
    "\n",
    "    # Divide the values in the \"off_duration (seconds)\" column by 20000\n",
    "    light_data[\"off_duration (seconds)\"] = light_data[\"off_duration (seconds)\"] / 20000\n",
    "\n",
    "    # Create a list \"light_times\" from the values in the first column\n",
    "    light_times = light_data.iloc[:, 0].tolist()\n",
    "    \n",
    "    sd = read_phy_files(dataset_path)\n",
    "    sd_start = sd.subtime(start*1000, stop*1000)\n",
    "\n",
    "    not_empties = []\n",
    "    empties = []\n",
    "    arrays = sd_start.train\n",
    "\n",
    "    for i, arr in enumerate(arrays):\n",
    "        if len(arr) > 0:\n",
    "            not_empties.append(i)\n",
    "        if len(arr) == 0:\n",
    "            empties.append(i)\n",
    "    \n",
    "    # Check if start is equal to or at most 10 above any number from light_data\n",
    "    if any(0 <= start - time <= 10 for time in light_times):\n",
    "        background_color = (0.6, 0.8, 0.4, 0.5)  # Lighter yellowgreen with an opacity of 0.5\n",
    "    else:\n",
    "        background_color = None\n",
    "\n",
    "    \n",
    "    sub_start = sd_start.subset(not_empties)\n",
    "\n",
    "    def latencies_mean(lat_list):\n",
    "        nested_list = lat_list\n",
    "        for i in range(len(nested_list)):\n",
    "            sublist = nested_list[i]\n",
    "            length = len(sublist)\n",
    "            if length == 0:\n",
    "                sublist_mean = 0\n",
    "            else:\n",
    "                sublist_mean = sum(sublist) / len(sublist)\n",
    "                sublist_mean = round(sublist_mean, 3)  # Round to 3d.p.\n",
    "            nested_list[i] = sublist_mean\n",
    "        return nested_list\n",
    "\n",
    "    def calculate_mean_latencies(sd):\n",
    "        num_neurons = sd.N\n",
    "        latencies_array = [None] * num_neurons\n",
    "\n",
    "        for curr_neuron in range(num_neurons):\n",
    "            latencies = latencies_mean(sd.latencies_to_index(curr_neuron))\n",
    "            latencies_array[curr_neuron] = latencies\n",
    "\n",
    "        return latencies_array\n",
    "\n",
    "    start_latencies = calculate_mean_latencies(sub_start)\n",
    "\n",
    "    def compute_in_out_degree(latencies_array):\n",
    "        num_neurons = len(latencies_array)\n",
    "        in_out_deg = [(0, 0) for _ in range(num_neurons)]\n",
    "\n",
    "        for curr_neuron in range(num_neurons):\n",
    "            in_deg = 0\n",
    "            out_deg = 0\n",
    "            curr_neural_latencies = latencies_array[curr_neuron]\n",
    "\n",
    "            for i in range(len(curr_neural_latencies)):\n",
    "                if curr_neural_latencies[i] > 0:\n",
    "                    out_deg += 1\n",
    "                if curr_neural_latencies[i] < 0:\n",
    "                    in_deg += 1\n",
    "\n",
    "            in_out_deg[curr_neuron] = (in_deg, out_deg)\n",
    "\n",
    "        return in_out_deg\n",
    "\n",
    "    start_in_out_deg = compute_in_out_degree(start_latencies)\n",
    "\n",
    "    def label_nodes(in_out_deg, frac_threshold=0.2):\n",
    "        node_info = ['grey'] * len(in_out_deg)\n",
    "\n",
    "        for i in range(len(in_out_deg)):\n",
    "            test1 = (in_out_deg[i][1] - in_out_deg[i][0]) / (in_out_deg[i][1] + in_out_deg[i][0])\n",
    "            test2 = (in_out_deg[i][0] - in_out_deg[i][1]) / (in_out_deg[i][1] + in_out_deg[i][0])\n",
    "\n",
    "            if test1 > frac_threshold:\n",
    "                node_info[i] = 'red'\n",
    "            if test2 > frac_threshold:\n",
    "                node_info[i] = 'blue'\n",
    "\n",
    "        return node_info\n",
    "\n",
    "    colors = label_nodes(start_in_out_deg)\n",
    "\n",
    "    def closest_value(number):\n",
    "        closest = 5\n",
    "        if abs(number - 20) < abs(number - closest):\n",
    "            closest = 20\n",
    "        if abs(number - 50) < abs(number - closest):\n",
    "            closest = 50\n",
    "        return closest\n",
    "\n",
    "    sub_start.neuron_data = sd_start.neuron_data\n",
    "    neur_data = sub_start.neuron_data[0]\n",
    "    for key in empties:\n",
    "        del neur_data[key]\n",
    "    sub_start.neuron_data[0] = neur_data\n",
    "\n",
    "    def sttc_neuron_plotter(inp_sd, upd_node_info, thresh):\n",
    "        neuron_x = []\n",
    "        neuron_y = []\n",
    "        neuron_amp = []\n",
    "\n",
    "        for neuron in inp_sd.neuron_data[0].values():\n",
    "            neuron_x.append(neuron['position'][0])\n",
    "            neuron_y.append(neuron['position'][1])\n",
    "            neuron_amp.append(np.mean(neuron['amplitudes']))\n",
    "\n",
    "        neuron_amp = [closest_value(num) for num in neuron_amp]\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(neuron_x, neuron_y, s=neuron_amp, c=upd_node_info)\n",
    "        \n",
    "        # Set the background color\n",
    "        if background_color:\n",
    "            plt.gca().set_facecolor(background_color)\n",
    "\n",
    "        threshold = thresh\n",
    "        sttc = inp_sd.spike_time_tilings()\n",
    "\n",
    "        for i in range(sttc.shape[0]):\n",
    "            for j in range(sttc.shape[1]):\n",
    "                if i <= j:\n",
    "                    continue\n",
    "                if sttc[i, j] < threshold:\n",
    "                    continue\n",
    "                if i in empties:\n",
    "                    continue\n",
    "                if j in empties:\n",
    "                    continue\n",
    "                ix, iy = inp_sd.neuron_data[0][i]['position']\n",
    "                jx, jy = inp_sd.neuron_data[0][j]['position']\n",
    "                linewidth = 1.5 + 2 * (sttc[i, j] - threshold)\n",
    "                opacity = 0.2 + 0.8 * (sttc[i, j] - threshold)\n",
    "                plt.plot([ix, jx], [iy, jy], linewidth=linewidth, c='grey', alpha=opacity)\n",
    "\n",
    "        plt.xlabel('um')\n",
    "        plt.ylabel('um')\n",
    "        plt.title(f\"{start} sec.png\")  # Adding the title\n",
    "\n",
    "        # Set fixed limits for x and y axes\n",
    "        plt.xlim(600, 1500)\n",
    "        plt.ylim(0, 2200)\n",
    "\n",
    "        node_degree_legend_elements = [\n",
    "            plt.scatter([], [], s=5, marker='o', edgecolor='black', facecolor='none', label='5'),\n",
    "            plt.scatter([], [], s=20, marker='o', edgecolor='black', facecolor='none', label='20'),\n",
    "            plt.scatter([], [], s=50, marker='o', edgecolor='black', facecolor='none', label='50')\n",
    "        ]\n",
    "\n",
    "        node_type_legend_elements = [\n",
    "            plt.scatter([], [], s=50, marker='o', edgecolor='black', facecolor='grey', label='Broker'),\n",
    "            plt.scatter([], [], s=50, marker='o', edgecolor='black', facecolor='red', label='Sender'),\n",
    "            plt.scatter([], [], s=50, marker='o', edgecolor='black', facecolor='blue', label='Receiver')\n",
    "        ]\n",
    "\n",
    "        node_degree_legend = plt.legend(handles=node_degree_legend_elements, title='Node Degree', loc='lower right')\n",
    "        plt.gca().add_artist(node_degree_legend)\n",
    "\n",
    "        correlation_legend_elements = [\n",
    "            plt.Line2D([0], [0], color='grey', linewidth=0.5, label='0.6'),\n",
    "            plt.Line2D([0], [0], color='grey', linewidth=1.0, label='0.8'),\n",
    "            plt.Line2D([0], [0], color='grey', linewidth=1.5, label='1.0')\n",
    "        ]\n",
    "\n",
    "        correlation_legend = plt.legend(handles=correlation_legend_elements, title='Correlation', loc='lower left')\n",
    "        plt.gca().add_artist(correlation_legend)\n",
    "\n",
    "        node_type_legend = plt.legend(handles=node_type_legend_elements, title='Node Type', loc='best')\n",
    "        plt.savefig(f\"/home/jovyan/work/Human_Hippocampus/saved_plots/fcm_animations/dataset_{dataset_number}/{start}_sec.png\")\n",
    "        plt.close()\n",
    "\n",
    "    sttc_neuron_plotter(sub_start, colors, 0.6)\n",
    "    \n",
    "    light_times = light_data.iloc[:, 0].tolist()\n",
    "    return light_times\n",
    "\n",
    "    return f\"/home/jovyan/work/Human_Hippocampus/saved_plots/fcm_animations/dataset_{dataset_number}/{start}_sec.png\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a10f783",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'start' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m         period_frames[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msave(save_path, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGIF\u001b[39m\u001b[38;5;124m'\u001b[39m, append_images\u001b[38;5;241m=\u001b[39mperiod_frames[\u001b[38;5;241m1\u001b[39m:], save_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Call the create_animated_gif function with the desired dataset_number\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[43mcreate_animated_gif\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 18\u001b[0m, in \u001b[0;36mcreate_animated_gif\u001b[0;34m(dataset_number)\u001b[0m\n\u001b[1;32m     15\u001b[0m length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(sd\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m) \n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Call the analyze_data function to get light_times\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m light_times \u001b[38;5;241m=\u001b[39m analyze_data(\u001b[43mstart\u001b[49m, stop, dataset_number)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Get the list of green background periods from the light_data\u001b[39;00m\n\u001b[1;32m     21\u001b[0m green_background_periods \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'start' referenced before assignment"
     ]
    }
   ],
   "source": [
    "def create_animated_gif(dataset_number):\n",
    "    # Define the directory path\n",
    "    directory = '/home/jovyan/work/Human_Hippocampus/saved_plots/firing_animations/'\n",
    "\n",
    "    # Create a subdirectory to save the figures\n",
    "    figures_directory = os.path.join(directory, f\"dataset_{dataset_number}\")\n",
    "    if not os.path.exists(figures_directory):\n",
    "        os.makedirs(figures_directory)\n",
    "\n",
    "    # Path for the dataset\n",
    "    dataset_path = f\"/home/jovyan/work/Human_Hippocampus/data/ephys/2023-04-02-hc328_rec/derived/kilosort2/2023_04_02_hc328_{dataset_number}_curated.zip\"\n",
    "    \n",
    "    # Assuming `read_phy_files` function is defined and properly imported.\n",
    "    sd = read_phy_files(dataset_path)\n",
    "    length = int(sd.length / 1000) \n",
    "    \n",
    "    \n",
    "    # Call the analyze_data function to get light_times\n",
    "    light_times = analyze_data(start, stop, dataset_number)\n",
    "\n",
    "    # Get the list of green background periods from the light_data\n",
    "    green_background_periods = []\n",
    "    prev_time = None\n",
    "    for time in light_times:\n",
    "        if prev_time is not None and time - prev_time > 10:\n",
    "            green_background_periods.append((prev_time, time))\n",
    "        prev_time = time\n",
    "\n",
    "    # Iterate over each green background period and create GIFs\n",
    "    for period_idx, (start, stop) in enumerate(green_background_periods):\n",
    "        # Create a subdirectory for each green background period\n",
    "        period_directory = os.path.join(figures_directory, f\"period_{period_idx}\")\n",
    "        if not os.path.exists(period_directory):\n",
    "            os.makedirs(period_directory)\n",
    "\n",
    "        # Iterate over each half-second of the period\n",
    "        for half_second in range(int(start * 2), int(stop * 2)):\n",
    "            start_time = half_second / 2\n",
    "            stop_time = start_time + 0.5\n",
    "\n",
    "            # Call analyze_data function for each half-second of the period\n",
    "            image_path = analyze_data(start_time, stop_time, dataset_number)\n",
    "            print(f\"Generated image: {image_path}\")\n",
    "\n",
    "        # Directory path where the PNG files are located\n",
    "        period_files = sorted([filename for filename in os.listdir(period_directory) if filename.endswith('.png')], key=lambda x: int(re.search(r'\\d+', x).group()))\n",
    "\n",
    "        # Create a list to store the image frames for each GIF\n",
    "        period_frames = []\n",
    "\n",
    "        # Iterate over each file and add it to the frames list\n",
    "        for filename in period_files:\n",
    "            # Create the full file path\n",
    "            file_path = os.path.join(period_directory, filename)\n",
    "\n",
    "            # Open the image file and append it to the frames list\n",
    "            image = Image.open(file_path)\n",
    "            period_frames.append(image)\n",
    "\n",
    "        # Save the frames as an animated GIF for each green background period\n",
    "        save_path = os.path.join(period_directory, f\"Dataset_{dataset_number}_Period_{period_idx}.gif\")\n",
    "        period_frames[0].save(save_path, format='GIF', append_images=period_frames[1:], save_all=True, duration=200, loop=0)\n",
    "\n",
    "# Call the create_animated_gif function with the desired dataset_number\n",
    "create_animated_gif(6)\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
