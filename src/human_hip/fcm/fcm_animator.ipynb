{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf7075df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "import scipy.ndimage as ndimage\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.lines import Line2D\n",
    "from PIL import Image\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import braingeneers\n",
    "import braingeneers.data.datasets_electrophysiology as ephys\n",
    "from braingeneers.analysis.analysis import SpikeData, read_phy_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f31c7c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data(start, stop, dataset_number):\n",
    "    dataset_path = f\"/home/jovyan/work/Human_Hippocampus/data/ephys/2023-04-02-hc328_rec/derived/kilosort2/2023_04_02_hc328_{dataset_number}_curated.zip\"\n",
    "    \n",
    "    # Map dataset_number to the corresponding light_data file\n",
    "    light_data_files = {\n",
    "        0: \"20230402T140926-2023_04_02_hc328_0_opto_stim_log.csv\",\n",
    "        1: \"20230402T141431-2023_04_02_hc328_1_opto_stim_log.csv\",\n",
    "        2: \"20230402T142358-2023_04_02_hc328_2_opto_stim_log.csv\",\n",
    "        3: \"20230402T142533-2023_04_02_hc328_3_opto_stim_log.csv\",\n",
    "        4: \"20230402T142658-2023_04_02_hc328_4_opto_stim_log.csv\",\n",
    "        5: \"20230402T142907-2023_04_02_hc328_5_opto_stim_log.csv\",\n",
    "        6: \"20230402T144122-2023_04_02_hc328_6_opto_stim_log.csv\",\n",
    "        7: \"20230402T145210-2023_04_02_hc328_7_opto_stim_log.csv\"\n",
    "    }\n",
    "\n",
    "    # Check if the dataset_number is valid\n",
    "    if dataset_number not in light_data_files:\n",
    "        raise ValueError(\"Invalid dataset_number\")\n",
    "\n",
    "    # Get the corresponding light_data file\n",
    "    light_data_file = light_data_files[dataset_number]\n",
    "\n",
    "    # Construct the light_data_path\n",
    "    light_data_path = f\"/home/jovyan/work/Human_Hippocampus/data/opto/hc328_20230402T14/{light_data_file}\"\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    light_data = pd.read_csv(light_data_path)\n",
    "\n",
    "\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    light_data = pd.read_csv(light_data_path)\n",
    "\n",
    "    # Rename the \"time (sec)\" column\n",
    "    light_data = light_data.rename(columns={\"time (sec)\": \"time change (sec)\"})\n",
    "    \n",
    "    # Calculate the time change values by subtracting the first value from each subsequent value\n",
    "    light_data[\"time change (sec)\"] = light_data[\"time change (sec)\"] - light_data.at[0, \"time change (sec)\"]\n",
    "\n",
    "    # Modify the values in the \"time change (sec)\" column based on the dataset number\n",
    "    if dataset_number == 5:\n",
    "        light_data[\"time change (sec)\"] = light_data[\"time change (sec)\"] + 10\n",
    "    elif dataset_number == 6:\n",
    "        light_data[\"time change (sec)\"] = light_data[\"time change (sec)\"] + 1\n",
    "\n",
    "    # Rename the \"on_duration (frames)\" column\n",
    "    light_data = light_data.rename(columns={\"on_duration (frames)\": \"on_duration (seconds)\"})\n",
    "\n",
    "    # Divide the values in the \"on_duration (seconds)\" column by 20000\n",
    "    light_data[\"on_duration (seconds)\"] = light_data[\"on_duration (seconds)\"] / 20000\n",
    "\n",
    "    # Rename the \"off_duration (frames)\" column\n",
    "    light_data = light_data.rename(columns={\"off_duration (frames)\": \"off_duration (seconds)\"})\n",
    "\n",
    "    # Divide the values in the \"off_duration (seconds)\" column by 20000\n",
    "    light_data[\"off_duration (seconds)\"] = light_data[\"off_duration (seconds)\"] / 20000\n",
    "\n",
    "    # Create a list \"light_times\" from the values in the first column\n",
    "    light_times = light_data.iloc[:, 0].tolist()\n",
    "    \n",
    "    sd = read_phy_files(dataset_path)\n",
    "    sd_start = sd.subtime(start*1000, stop*1000)\n",
    "\n",
    "    not_empties = []\n",
    "    empties = []\n",
    "    arrays = sd_start.train\n",
    "\n",
    "    for i, arr in enumerate(arrays):\n",
    "        if len(arr) > 0:\n",
    "            not_empties.append(i)\n",
    "        if len(arr) == 0:\n",
    "            empties.append(i)\n",
    "    \n",
    "    # Check if start is equal to or at most 10 above any number from light_data\n",
    "    if any(0 <= start - time <= 10 for time in light_times):\n",
    "        background_color = (0.6, 0.8, 0.4, 0.5)  # Lighter yellowgreen with an opacity of 0.5\n",
    "    else:\n",
    "        background_color = None\n",
    "\n",
    "    \n",
    "    sub_start = sd_start.subset(not_empties)\n",
    "\n",
    "    def latencies_mean(lat_list):\n",
    "        nested_list = lat_list\n",
    "        for i in range(len(nested_list)):\n",
    "            sublist = nested_list[i]\n",
    "            length = len(sublist)\n",
    "            if length == 0:\n",
    "                sublist_mean = 0\n",
    "            else:\n",
    "                sublist_mean = sum(sublist) / len(sublist)\n",
    "                sublist_mean = round(sublist_mean, 3)  # Round to 3d.p.\n",
    "            nested_list[i] = sublist_mean\n",
    "        return nested_list\n",
    "\n",
    "    def calculate_mean_latencies(sd):\n",
    "        num_neurons = sd.N\n",
    "        latencies_array = [None] * num_neurons\n",
    "\n",
    "        for curr_neuron in range(num_neurons):\n",
    "            latencies = latencies_mean(sd.latencies_to_index(curr_neuron))\n",
    "            latencies_array[curr_neuron] = latencies\n",
    "\n",
    "        return latencies_array\n",
    "\n",
    "    start_latencies = calculate_mean_latencies(sub_start)\n",
    "\n",
    "    def compute_in_out_degree(latencies_array):\n",
    "        num_neurons = len(latencies_array)\n",
    "        in_out_deg = [(0, 0) for _ in range(num_neurons)]\n",
    "\n",
    "        for curr_neuron in range(num_neurons):\n",
    "            in_deg = 0\n",
    "            out_deg = 0\n",
    "            curr_neural_latencies = latencies_array[curr_neuron]\n",
    "\n",
    "            for i in range(len(curr_neural_latencies)):\n",
    "                if curr_neural_latencies[i] > 0:\n",
    "                    out_deg += 1\n",
    "                if curr_neural_latencies[i] < 0:\n",
    "                    in_deg += 1\n",
    "\n",
    "            in_out_deg[curr_neuron] = (in_deg, out_deg)\n",
    "\n",
    "        return in_out_deg\n",
    "\n",
    "    start_in_out_deg = compute_in_out_degree(start_latencies)\n",
    "\n",
    "    def label_nodes(in_out_deg, frac_threshold=0.2):\n",
    "        node_info = ['grey'] * len(in_out_deg)\n",
    "\n",
    "        for i in range(len(in_out_deg)):\n",
    "            test1 = (in_out_deg[i][1] - in_out_deg[i][0]) / (in_out_deg[i][1] + in_out_deg[i][0])\n",
    "            test2 = (in_out_deg[i][0] - in_out_deg[i][1]) / (in_out_deg[i][1] + in_out_deg[i][0])\n",
    "\n",
    "            if test1 > frac_threshold:\n",
    "                node_info[i] = 'red'\n",
    "            if test2 > frac_threshold:\n",
    "                node_info[i] = 'blue'\n",
    "\n",
    "        return node_info\n",
    "\n",
    "    colors = label_nodes(start_in_out_deg)\n",
    "\n",
    "    def closest_value(number):\n",
    "        closest = 5\n",
    "        if abs(number - 20) < abs(number - closest):\n",
    "            closest = 20\n",
    "        if abs(number - 50) < abs(number - closest):\n",
    "            closest = 50\n",
    "        return closest\n",
    "\n",
    "    sub_start.neuron_data = sd_start.neuron_data\n",
    "    neur_data = sub_start.neuron_data[0]\n",
    "    for key in empties:\n",
    "        del neur_data[key]\n",
    "    sub_start.neuron_data[0] = neur_data\n",
    "\n",
    "    def sttc_neuron_plotter(inp_sd, upd_node_info, thresh):\n",
    "        neuron_x = []\n",
    "        neuron_y = []\n",
    "        neuron_amp = []\n",
    "\n",
    "        for neuron in inp_sd.neuron_data[0].values():\n",
    "            neuron_x.append(neuron['position'][0])\n",
    "            neuron_y.append(neuron['position'][1])\n",
    "            neuron_amp.append(np.mean(neuron['amplitudes']))\n",
    "\n",
    "        neuron_amp = [closest_value(num) for num in neuron_amp]\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(neuron_x, neuron_y, s=neuron_amp, c=upd_node_info)\n",
    "        \n",
    "        # Set the background color\n",
    "        if background_color:\n",
    "            plt.gca().set_facecolor(background_color)\n",
    "\n",
    "        threshold = thresh\n",
    "        sttc = inp_sd.spike_time_tilings()\n",
    "\n",
    "        for i in range(sttc.shape[0]):\n",
    "            for j in range(sttc.shape[1]):\n",
    "                if i <= j:\n",
    "                    continue\n",
    "                if sttc[i, j] < threshold:\n",
    "                    continue\n",
    "                if i in empties:\n",
    "                    continue\n",
    "                if j in empties:\n",
    "                    continue\n",
    "                ix, iy = inp_sd.neuron_data[0][i]['position']\n",
    "                jx, jy = inp_sd.neuron_data[0][j]['position']\n",
    "                linewidth = 1.5 + 2 * (sttc[i, j] - threshold)\n",
    "                opacity = 0.2 + 0.8 * (sttc[i, j] - threshold)\n",
    "                plt.plot([ix, jx], [iy, jy], linewidth=linewidth, c='grey', alpha=opacity)\n",
    "\n",
    "        plt.xlabel('um')\n",
    "        plt.ylabel('um')\n",
    "        plt.title(f\"{start} sec.png\")  # Adding the title\n",
    "\n",
    "        # Set fixed limits for x and y axes\n",
    "        plt.xlim(600, 1500)\n",
    "        plt.ylim(0, 2200)\n",
    "\n",
    "        node_degree_legend_elements = [\n",
    "            plt.scatter([], [], s=5, marker='o', edgecolor='black', facecolor='none', label='5'),\n",
    "            plt.scatter([], [], s=20, marker='o', edgecolor='black', facecolor='none', label='20'),\n",
    "            plt.scatter([], [], s=50, marker='o', edgecolor='black', facecolor='none', label='50')\n",
    "        ]\n",
    "\n",
    "        node_type_legend_elements = [\n",
    "            plt.scatter([], [], s=50, marker='o', edgecolor='black', facecolor='grey', label='Broker'),\n",
    "            plt.scatter([], [], s=50, marker='o', edgecolor='black', facecolor='red', label='Sender'),\n",
    "            plt.scatter([], [], s=50, marker='o', edgecolor='black', facecolor='blue', label='Receiver')\n",
    "        ]\n",
    "\n",
    "        node_degree_legend = plt.legend(handles=node_degree_legend_elements, title='Node Degree', loc='lower right')\n",
    "        plt.gca().add_artist(node_degree_legend)\n",
    "\n",
    "        correlation_legend_elements = [\n",
    "            plt.Line2D([0], [0], color='grey', linewidth=0.5, label='0.6'),\n",
    "            plt.Line2D([0], [0], color='grey', linewidth=1.0, label='0.8'),\n",
    "            plt.Line2D([0], [0], color='grey', linewidth=1.5, label='1.0')\n",
    "        ]\n",
    "\n",
    "        correlation_legend = plt.legend(handles=correlation_legend_elements, title='Correlation', loc='lower left')\n",
    "        plt.gca().add_artist(correlation_legend)\n",
    "\n",
    "        node_type_legend = plt.legend(handles=node_type_legend_elements, title='Node Type', loc='best')\n",
    "        plt.savefig(f\"/home/jovyan/work/Human_Hippocampus/saved_plots/fcm_animations/dataset_{dataset_number}/{start}_sec.png\")\n",
    "        plt.close()\n",
    "\n",
    "    sttc_neuron_plotter(sub_start, colors, 0.6)\n",
    "\n",
    "    return f\"/home/jovyan/work/Human_Hippocampus/saved_plots/fcm_animations/dataset_{dataset_number}/{start}_sec.png\"\n",
    "\n",
    "def create_animated_gif(dataset_number):\n",
    "    # TODO: Make the directory a parameter you can set in the function\n",
    "    \n",
    "    # Define the directory path\n",
    "    directory = '/home/jovyan/work/Human_Hippocampus/saved_plots/fcm_animations/'\n",
    "\n",
    "    # Create a subdirectory to save the figures\n",
    "    figures_directory = os.path.join(directory, f\"dataset_{dataset_number}\")\n",
    "    if not os.path.exists(figures_directory):\n",
    "        os.makedirs(figures_directory)\n",
    "    dataset_path = f\"/home/jovyan/data/ephys/2023-04-02-hc328_rec/derived/kilosort2/2023_04_02_hc328_{dataset_number}_curated.zip\"\n",
    "    \n",
    "    sd = read_phy_files(dataset_path)\n",
    "    length = int(sd.length/1000) \n",
    "    \n",
    "    # Iterate over each second of the data\n",
    "    for second in range(length):\n",
    "        start = second\n",
    "        stop = second + 1\n",
    "\n",
    "        # Call analyze_data function\n",
    "        image_path = analyze_data(start, stop, dataset_number)\n",
    "        print(f\"Generated image: {image_path}\")\n",
    "\n",
    "    # Directory path where the PNG files are located\n",
    "    directory = figures_directory\n",
    "\n",
    "    # Create a list of file names in the directory\n",
    "    file_list = sorted([filename for filename in os.listdir(directory) if filename.endswith('.png')], key=lambda x: int(re.search(r'\\d+', x).group()))\n",
    "\n",
    "    # Create a list to store the image frames\n",
    "    frames = []\n",
    "\n",
    "    # Iterate over each file and add it to the frames list\n",
    "    for filename in file_list:\n",
    "        # Create the full file path\n",
    "        file_path = os.path.join(directory, filename)\n",
    "\n",
    "        # Open the image file and append it to the frames list\n",
    "        image = Image.open(file_path)\n",
    "        frames.append(image)\n",
    "\n",
    "    # Save the frames as an animated GIF\n",
    "    save_path = \"/home/jovyan/work/Human_Hippocampus/saved_plots/fcm_animations/\" + f\"Dataset_{dataset_number}.gif\"\n",
    "    frames[0].save(save_path, format='GIF', append_images=frames[1:], save_all=True, duration=400, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a5ff8df",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jovyan/work/Human_Hippocampus/data/ephys/2023-04-02-hc328_rec/derived/kilosort2/2023_04_02_hc328_6_curated.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/human_hippocampus/src/human_hip/fcm/fcm_animator.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bpotential-space-barnacle-xjw6q5jqrx726g6p/workspaces/human_hippocampus/src/human_hip/fcm/fcm_animator.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Example usage\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bpotential-space-barnacle-xjw6q5jqrx726g6p/workspaces/human_hippocampus/src/human_hip/fcm/fcm_animator.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m create_animated_gif(dataset_number\u001b[39m=\u001b[39;49m\u001b[39m6\u001b[39;49m)\n",
      "\u001b[1;32m/workspaces/human_hippocampus/src/human_hip/fcm/fcm_animator.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://codespaces%2Bpotential-space-barnacle-xjw6q5jqrx726g6p/workspaces/human_hippocampus/src/human_hip/fcm/fcm_animator.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=245'>246</a>\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(figures_directory)\n\u001b[1;32m    <a href='vscode-notebook-cell://codespaces%2Bpotential-space-barnacle-xjw6q5jqrx726g6p/workspaces/human_hippocampus/src/human_hip/fcm/fcm_animator.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=246'>247</a>\u001b[0m dataset_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/home/jovyan/work/Human_Hippocampus/data/ephys/2023-04-02-hc328_rec/derived/kilosort2/2023_04_02_hc328_\u001b[39m\u001b[39m{\u001b[39;00mdataset_number\u001b[39m}\u001b[39;00m\u001b[39m_curated.zip\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> <a href='vscode-notebook-cell://codespaces%2Bpotential-space-barnacle-xjw6q5jqrx726g6p/workspaces/human_hippocampus/src/human_hip/fcm/fcm_animator.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=248'>249</a>\u001b[0m sd \u001b[39m=\u001b[39m read_phy_files(dataset_path)\n\u001b[1;32m    <a href='vscode-notebook-cell://codespaces%2Bpotential-space-barnacle-xjw6q5jqrx726g6p/workspaces/human_hippocampus/src/human_hip/fcm/fcm_animator.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=249'>250</a>\u001b[0m length \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(sd\u001b[39m.\u001b[39mlength\u001b[39m/\u001b[39m\u001b[39m1000\u001b[39m) \n\u001b[1;32m    <a href='vscode-notebook-cell://codespaces%2Bpotential-space-barnacle-xjw6q5jqrx726g6p/workspaces/human_hippocampus/src/human_hip/fcm/fcm_animator.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=251'>252</a>\u001b[0m \u001b[39m# Iterate over each second of the data\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/braingeneers/analysis/analysis.py:239\u001b[0m, in \u001b[0;36mread_phy_files\u001b[0;34m(path, fs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39massert\u001b[39;00m path[\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m:] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzip\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mOnly zip files supported!\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    238\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbraingeneers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msmart_open_braingeneers\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msmart_open\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m \u001b[39mwith\u001b[39;00m smart_open\u001b[39m.\u001b[39;49mopen(path, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f0:\n\u001b[1;32m    240\u001b[0m     f \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO(f0\u001b[39m.\u001b[39mread())\n\u001b[1;32m    242\u001b[0m     \u001b[39mwith\u001b[39;00m zipfile\u001b[39m.\u001b[39mZipFile(f, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f_zip:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/braingeneers/utils/smart_open_braingeneers/__init__.py:14\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     10\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m    Simple hand off to smart_open, this explicit handoff is required because open can reference a\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m    new function if configure.set_default_endpoint is called in the future.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     \u001b[39mreturn\u001b[39;00m braingeneers\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mconfigure\u001b[39m.\u001b[39;49m_open(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/smart_open/smart_open_lib.py:177\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m transport_params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     transport_params \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 177\u001b[0m fobj \u001b[39m=\u001b[39m _shortcut_open(\n\u001b[1;32m    178\u001b[0m     uri,\n\u001b[1;32m    179\u001b[0m     mode,\n\u001b[1;32m    180\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    181\u001b[0m     buffering\u001b[39m=\u001b[39;49mbuffering,\n\u001b[1;32m    182\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    183\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    184\u001b[0m     newline\u001b[39m=\u001b[39;49mnewline,\n\u001b[1;32m    185\u001b[0m )\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[39mreturn\u001b[39;00m fobj\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/smart_open/smart_open_lib.py:363\u001b[0m, in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m errors \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m    361\u001b[0m     open_kwargs[\u001b[39m'\u001b[39m\u001b[39merrors\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m errors\n\u001b[0;32m--> 363\u001b[0m \u001b[39mreturn\u001b[39;00m _builtin_open(local_path, mode, buffering\u001b[39m=\u001b[39;49mbuffering, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mopen_kwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jovyan/work/Human_Hippocampus/data/ephys/2023-04-02-hc328_rec/derived/kilosort2/2023_04_02_hc328_6_curated.zip'"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "create_animated_gif(dataset_number=6)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
