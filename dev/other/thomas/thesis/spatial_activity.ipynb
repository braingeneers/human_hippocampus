{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                     \n",
    "import pandas as pd\n",
    "import random as rand\n",
    "from scipy.signal import correlate, correlation_lags\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "import matplotlib.pyplot as plt       \n",
    "from matplotlib.patches import FancyArrow, Patch, Circle\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import braingeneers                  \n",
    "from braingeneers.analysis.analysis import SpikeData, read_phy_files, load_spike_data, burst_detection, randomize_raster\n",
    "import braingeneers.data.datasets_electrophysiology as ephys\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64595/653605344.py:1: DeprecationWarning: Call to deprecated function (or staticmethod) read_phy_files. (Prefer load_spike_data()) -- Deprecated since version 0.1.13.\n",
      "  sd = read_phy_files('/workspaces/human_hippocampus/data/ephys/2023-04-02-e-hc328_unperturbed/derived/kilosort2/hc3.28_hckcr1_chip16835_plated34.2_rec4.2_curated.zip')\n"
     ]
    }
   ],
   "source": [
    "sd = read_phy_files('/workspaces/human_hippocampus/data/ephys/2023-04-02-e-hc328_unperturbed/derived/kilosort2/hc3.28_hckcr1_chip16835_plated34.2_rec4.2_curated.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_firing_rates(spike_data):\n",
    "    # Compute mean firing rates for each neuron\n",
    "    firing_rates = [len(train) / spike_data.length for train in spike_data.train]\n",
    "    return firing_rates\n",
    "\n",
    "def get_neuron_positions(spike_data):\n",
    "    # Extract neuron positions from spike_data\n",
    "    neuron_x = []\n",
    "    neuron_y = []\n",
    "    for neuron in spike_data.neuron_data[0].values():\n",
    "        neuron_x.append(neuron['position'][0])\n",
    "        neuron_y.append(neuron['position'][1])\n",
    "    neuron_positions = np.array([neuron_x, neuron_y]).T\n",
    "    return neuron_positions\n",
    "\n",
    "def precalculate_distances_angles(neuron_positions):\n",
    "    # Vectorized calculation of distances\n",
    "    diff = neuron_positions[:, np.newaxis, :] - neuron_positions[np.newaxis, :, :]\n",
    "    distances = np.sqrt(np.sum(diff**2, axis=2))\n",
    "    \n",
    "    # Vectorized calculation of angles\n",
    "    angles = np.arctan2(diff[..., 1], diff[..., 0]) % (2 * np.pi)\n",
    "    \n",
    "    return distances, angles\n",
    "\n",
    "\n",
    "def create_reverse_rank_lookup(event_ranks):\n",
    "    \"\"\"\n",
    "    Create a reverse lookup table for event ranks.\n",
    "    \n",
    "    Parameters:\n",
    "    - event_ranks: A dictionary mapping (neuron_id, spike_time) to event rank.\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary mapping event rank to (neuron_id, spike_time).\n",
    "    \"\"\"\n",
    "    reverse_lookup = {rank: (neuron_id, spike_time) for (neuron_id, spike_time), rank in event_ranks.items()}\n",
    "    return reverse_lookup \n",
    "\n",
    "def calculate_event_ranks(spike_data, precision=5):\n",
    "    # Flatten the list of spikes, rounding spike times, and sort by time\n",
    "    # Include the original index of each spike for uniqueness\n",
    "    all_spikes = [(neuron_id, round(spike_time, precision), idx) \n",
    "                  for neuron_id, spikes in enumerate(spike_data.train) \n",
    "                  for idx, spike_time in enumerate(spikes)]\n",
    "                  \n",
    "    # Sort by neuron_id, then rounded spike time, then original index\n",
    "    all_spikes_sorted = sorted(all_spikes, key=lambda x: (x[1], x[0], x[2]))\n",
    "    \n",
    "    # Generate a dictionary with event rank as key, (neuron_id, spike_time) as value\n",
    "    ranks = {rank: (neuron_id, spike_time) for rank, (neuron_id, spike_time, _) in enumerate(all_spikes_sorted)}\n",
    "    \n",
    "    print(f\"Total unique events: {len(ranks)}\")\n",
    "    \n",
    "    return ranks\n",
    "\n",
    "def precompute_close_neurons(distances, window_size=17.5):\n",
    "    close_neurons = {}\n",
    "    for i in range(len(distances)):\n",
    "        close_neurons[i] = [j for j in range(len(distances)) if i != j and distances[i, j] < window_size]\n",
    "    return close_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_histograms_for_events(spike_data, event_ranks, spatial_range=(82, 1092), time_window_rank=30, bins=6):\n",
    "    total_events = len(event_ranks)\n",
    "\n",
    "    histograms_for_each_event = {}\n",
    "\n",
    "    distances = precalculate_distances_angles(get_neuron_positions(spike_data))[0]\n",
    "    angles = precalculate_distances_angles(get_neuron_positions(spike_data))[1]\n",
    "\n",
    "    distance_bins = np.linspace(0, np.max(distances), bins+1)\n",
    "    angle_bins = np.linspace(0, 2*np.pi, bins+1)\n",
    "\n",
    "    print_every_n = max(total_events // 100, 1)  # Update progress every 10% or at least once\n",
    "    \n",
    "    for current_event_id in event_ranks:\n",
    "        if current_event_id % print_every_n == 0:\n",
    "            print(f\"Processing event {current_event_id + 1}/{total_events}...\")\n",
    "            \n",
    "        start_rank = max(0, current_event_id - time_window_rank)\n",
    "        end_rank = min(total_events, current_event_id + time_window_rank + 1)\n",
    "\n",
    "        event_distances, event_angles = [], []\n",
    "\n",
    "        # Only consider events within the rank window\n",
    "        for other_event_id in range(start_rank, end_rank):\n",
    "            if other_event_id == current_event_id:\n",
    "                continue\n",
    "\n",
    "            current_neuron_id = event_ranks[current_event_id][0]\n",
    "            other_neuron_id = event_ranks[other_event_id][0]\n",
    "\n",
    "            # Lookup distance and angle between the two neurons\n",
    "            distance = distances[current_neuron_id, other_neuron_id]\n",
    "            angle = angles[current_neuron_id, other_neuron_id]\n",
    "\n",
    "            if spatial_range[0] < distance < spatial_range[1]:\n",
    "                event_distances.append(distance)\n",
    "                event_angles.append(angle)\n",
    "\n",
    "        distance_hist, _ = np.histogram(event_distances, bins=distance_bins)\n",
    "        angle_hist, _ = np.histogram(event_angles, bins=angle_bins)\n",
    "\n",
    "        histograms_for_each_event[current_event_id] = {\n",
    "            'distance': distance_hist,\n",
    "            'angle': angle_hist\n",
    "        }\n",
    "    \n",
    "    print(\"Processing complete\")\n",
    "    return histograms_for_each_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique events: 113477\n",
      "Processing event 1/113477...\n",
      "Processing event 1135/113477...\n",
      "Processing event 2269/113477...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64595/2324574115.py:10: DeprecationWarning: Call to deprecated function (or staticmethod) neuron_data. (Use NeuronAttributes instead of neuron_data, with the function load_spike_data())\n",
      "  for neuron in spike_data.neuron_data[0].values():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing event 3403/113477...\n",
      "Processing event 4537/113477...\n",
      "Processing event 5671/113477...\n",
      "Processing event 6805/113477...\n",
      "Processing event 7939/113477...\n",
      "Processing event 9073/113477...\n",
      "Processing event 10207/113477...\n",
      "Processing event 11341/113477...\n",
      "Processing event 12475/113477...\n",
      "Processing event 13609/113477...\n",
      "Processing event 14743/113477...\n",
      "Processing event 15877/113477...\n",
      "Processing event 17011/113477...\n",
      "Processing event 18145/113477...\n",
      "Processing event 19279/113477...\n",
      "Processing event 20413/113477...\n",
      "Processing event 21547/113477...\n",
      "Processing event 22681/113477...\n",
      "Processing event 23815/113477...\n",
      "Processing event 24949/113477...\n",
      "Processing event 26083/113477...\n",
      "Processing event 27217/113477...\n",
      "Processing event 28351/113477...\n",
      "Processing event 29485/113477...\n",
      "Processing event 30619/113477...\n",
      "Processing event 31753/113477...\n",
      "Processing event 32887/113477...\n",
      "Processing event 34021/113477...\n",
      "Processing event 35155/113477...\n",
      "Processing event 36289/113477...\n",
      "Processing event 37423/113477...\n",
      "Processing event 38557/113477...\n",
      "Processing event 39691/113477...\n",
      "Processing event 40825/113477...\n",
      "Processing event 41959/113477...\n",
      "Processing event 43093/113477...\n",
      "Processing event 44227/113477...\n",
      "Processing event 45361/113477...\n",
      "Processing event 46495/113477...\n",
      "Processing event 47629/113477...\n",
      "Processing event 48763/113477...\n",
      "Processing event 49897/113477...\n",
      "Processing event 51031/113477...\n",
      "Processing event 52165/113477...\n",
      "Processing event 53299/113477...\n",
      "Processing event 54433/113477...\n",
      "Processing event 55567/113477...\n",
      "Processing event 56701/113477...\n",
      "Processing event 57835/113477...\n",
      "Processing event 58969/113477...\n",
      "Processing event 60103/113477...\n",
      "Processing event 61237/113477...\n",
      "Processing event 62371/113477...\n",
      "Processing event 63505/113477...\n",
      "Processing event 64639/113477...\n",
      "Processing event 65773/113477...\n",
      "Processing event 66907/113477...\n",
      "Processing event 68041/113477...\n",
      "Processing event 69175/113477...\n",
      "Processing event 70309/113477...\n",
      "Processing event 71443/113477...\n",
      "Processing event 72577/113477...\n",
      "Processing event 73711/113477...\n",
      "Processing event 74845/113477...\n",
      "Processing event 75979/113477...\n",
      "Processing event 77113/113477...\n",
      "Processing event 78247/113477...\n",
      "Processing event 79381/113477...\n",
      "Processing event 80515/113477...\n",
      "Processing event 81649/113477...\n",
      "Processing event 82783/113477...\n",
      "Processing event 83917/113477...\n",
      "Processing event 85051/113477...\n",
      "Processing event 86185/113477...\n",
      "Processing event 87319/113477...\n",
      "Processing event 88453/113477...\n",
      "Processing event 89587/113477...\n",
      "Processing event 90721/113477...\n",
      "Processing event 91855/113477...\n",
      "Processing event 92989/113477...\n",
      "Processing event 94123/113477...\n",
      "Processing event 95257/113477...\n",
      "Processing event 96391/113477...\n",
      "Processing event 97525/113477...\n",
      "Processing event 98659/113477...\n",
      "Processing event 99793/113477...\n",
      "Processing event 100927/113477...\n",
      "Processing event 102061/113477...\n",
      "Processing event 103195/113477...\n",
      "Processing event 104329/113477...\n",
      "Processing event 105463/113477...\n",
      "Processing event 106597/113477...\n",
      "Processing event 107731/113477...\n",
      "Processing event 108865/113477...\n",
      "Processing event 109999/113477...\n",
      "Processing event 111133/113477...\n",
      "Processing event 112267/113477...\n",
      "Processing event 113401/113477...\n",
      "Processing complete\n"
     ]
    }
   ],
   "source": [
    "event_ranks = calculate_event_ranks(sd)\n",
    "histograms = create_histograms_for_events(sd, event_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113477"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(histograms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
