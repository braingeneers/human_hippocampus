{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06881422",
   "metadata": {},
   "source": [
    "<font size=7> Basic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a78245",
   "metadata": {},
   "source": [
    "This notebook contains the code used to run some basic sanity checks on a selected dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d66ac9",
   "metadata": {},
   "source": [
    "<font color=\"red\">\n",
    "\n",
    "**To Do**\n",
    "* remove the unnecesary imports\n",
    "* for text summary, check that Tom's code produces same result as Aris code. You only have to check this for one file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfa9c7e",
   "metadata": {},
   "source": [
    "# Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b823e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\tLoading analysis source code...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21532676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fcm\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "import scipy.ndimage as ndimage\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Patch, Circle\n",
    "from matplotlib.lines import Line2D\n",
    "from PIL import Image\n",
    "import ipywidgets as ipw\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual  # package for interactive widgets \n",
    "import braingeneers                                                   # Braingeneers code\n",
    "from braingeneers.analysis.analysis import SpikeData, read_phy_files\n",
    "import braingeneers.data.datasets_electrophysiology as ephys\n",
    "from IPython.display import HTML, display, Javascript, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8c339c",
   "metadata": {},
   "source": [
    "# Create text Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85b6fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folders = os.listdir(\"/home/jovyan/data/ephys\")[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fcb77b",
   "metadata": {},
   "source": [
    "## <font color=\"gray\">Helper function to `analyze_spike_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f75d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_spike_data(sd):\n",
    "    idces_control, times_control = sd.idces_times()\n",
    "    n_neurons_control = len(sd.rates())\n",
    "\n",
    "    print(\"Number of spikes: \", len(idces_control))\n",
    "    print(\"Length: \", int(times_control[-1]/1000), \"seconds\")\n",
    "    print(\"Number of Neurons: \", n_neurons_control)\n",
    "    entire_firing_rate_control = len(idces_control) / (times_control[-1] / 1000)\n",
    "    avg_rate_control = entire_firing_rate_control / n_neurons_control\n",
    "    print(\"Average Firing Rate: \", round(avg_rate_control, 2))\n",
    "\n",
    "    isis_raw = sd.interspike_intervals()\n",
    "    # Remove all isi's greater than 100ms. As there are likely neurons not following periodic firing pattern\n",
    "    isis = []\n",
    "    for i in range(len(isis_raw)):\n",
    "        isi = isis_raw[i]\n",
    "        isis = isis + isi[isi < 100].tolist()\n",
    "\n",
    "    isi_mean = sum(isis) / len(isis)\n",
    "    isi_var = sum([((x - isi_mean) ** 2) for x in isis]) / len(isis)\n",
    "    isi_std = isi_var ** 0.5\n",
    "    cv = isi_std / isi_mean\n",
    "    print(\"Coefficient of Variation: \", round(cv,3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d476c4",
   "metadata": {},
   "source": [
    "## Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d29c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTextSummary(folder_name):\n",
    "    path = f\"/home/jovyan/data/ephys/{folder_name}/derived/kilosort2/\"\n",
    "    file_extension = \"_curated.zip\"\n",
    "    spike_data_objects = {}  # Dictionary to store spike data objects\n",
    "\n",
    "    def get_last_digit(s):\n",
    "        return int(''.join(filter(str.isdigit, s))[-1])\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(file_extension):\n",
    "            file_path = os.path.join(path, filename)\n",
    "            try:\n",
    "                sd = read_phy_files(file_path)\n",
    "                sd.original_file = filename\n",
    "                # Generating the unique name for the spike data object based on the last digit of the filename\n",
    "                sd_name = \"sd_\" + str(get_last_digit(filename))\n",
    "                spike_data_objects[sd_name] = sd\n",
    "            except:\n",
    "                print(f\"WARNING: Unable to Read < {filename} >\")\n",
    "    print(\"-----------------------------\")       \n",
    "    for sd_name in sorted(spike_data_objects.keys(), key=lambda x: int(x.split(\"_\")[-1])):\n",
    "        sd_object = spike_data_objects[sd_name]\n",
    "        #print(f\"Analyzing {sd_name}...\")\n",
    "        print(f\"Filename: {sd_object.original_file}:\")\n",
    "        analyze_spike_data(sd_object)\n",
    "        print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b545a8",
   "metadata": {},
   "source": [
    "# Create a Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedd0467",
   "metadata": {},
   "source": [
    "## <font color=\"gray\"> helper code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e8970d",
   "metadata": {},
   "source": [
    "Get firing rates of individual neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490bca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_firing_rates(spike_data):\n",
    "    mean_firing_rates = []\n",
    "    for neuron_spikes in spike_data.train:\n",
    "        num_spikes = len(neuron_spikes)\n",
    "        time_duration = spike_data.length / 1000  # Assuming spike times are in milliseconds\n",
    "        firing_rate = num_spikes / time_duration\n",
    "        mean_firing_rates.append(firing_rate)\n",
    "\n",
    "    return np.array(mean_firing_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f4f0fa",
   "metadata": {},
   "source": [
    "Interspike Interval of spikedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a01770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ISI(sd):\n",
    "    # Interspike-intervals of 2 select neurons\n",
    "    isis_raw = sd.interspike_intervals()\n",
    "    # Remove all isi's greater than 100ms. As there are likely neurons not following periodic firing pattern\n",
    "    isis=[]\n",
    "    for i in range(len(isis_raw)):   \n",
    "        isi=isis_raw[i]\n",
    "        isis = isis + isi[isi<100].tolist() \n",
    "        \n",
    "    return isis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3ff44f",
   "metadata": {},
   "source": [
    "Interspike Interval of individual Neural units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8bd5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IndivISI(sd, neuron):\n",
    "    # Interspike-intervals of individual neuron\n",
    "    neuronISIs = sd.interspike_intervals()[neuron];\n",
    "    isis = []\n",
    "    \n",
    "    for i in range(len(neuronISIs)):\n",
    "        if neuronISIs[i]<100:\n",
    "            isis.append(neuronISIs[i])\n",
    "            \n",
    "    return isis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac1a5f6",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748a3170",
   "metadata": {},
   "source": [
    "Get data filenames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fc9ffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "data_folders = !ls /home/jovyan/data/ephys\n",
    "for folder in data_folders:\n",
    "    files = !ls /home/jovyan/data/ephys/{folder}/derived/kilosort2/*curated*\n",
    "    filenames += files\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6442d9d",
   "metadata": {},
   "source": [
    "Main plotting function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d54ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPlots(filename):\n",
    "    global sd\n",
    "    # creates plots for spikedata analysis including: ISI hist, firing rate hist and layout, and Spikeraster of first 30 seconds\n",
    "    sd = read_phy_files(filename)\n",
    "    firing_rates = calculate_mean_firing_rates(sd)\n",
    "    seconds=30 # seconds to display raster\n",
    "    neuron_x = []\n",
    "    neuron_y = []\n",
    "    \n",
    "    for neuron in sd.neuron_data[0].values():\n",
    "        neuron_x.append(neuron[\"position\"][0])\n",
    "        neuron_y.append(neuron[\"position\"][1])\n",
    "    \n",
    "    # Plot main figure --------------------------------------------------------------------\n",
    "    figs, plots = plt.subplots(nrows=2,ncols=2,figsize=(12,12))\n",
    "    figs.suptitle(f\"Plots of recording: {filename}\", ha=\"center\")\n",
    "    \n",
    "    # Plot ISI Histogram subplot\n",
    "    plots[0,0].hist(ISI(sd), bins=50);\n",
    "    plots[0,0].set_title(\"Interspike Interval of Recording\")\n",
    "    plots[0,0].set_xlabel(\"Time bin(ms)\")\n",
    "    plots[0,0].set_ylabel(\"ISI count\")\n",
    "    \n",
    "    # Plot Firing Rates Histogram subplot\n",
    "    plots[0,1].hist(firing_rates);\n",
    "    plots[0,1].set_title(\"Average Firing Rate for Neural Units\") \n",
    "    plots[0,1].set_xlabel(\"Firing Rate(ms)\")\n",
    "    plots[0,1].set_ylabel(\"Unit Count\") \n",
    "    \n",
    "    # Plot Neuron Firing Rate Layout subplot\n",
    "    plots[1,0].scatter(neuron_x, neuron_y, s=firing_rates*100, c=\"red\", alpha=0.3)\n",
    "    #plots[1,0].scatter(neuron_x, neuron_y, s=(2**firing_rates)*10, c=\"red\", alpha=0.3)\n",
    "    plots[1,0].set_title(\"Neuron Firing Rate Across MEA\")\n",
    "    plots[1,0].set_xlabel(\"um\")\n",
    "    plots[1,0].set_ylabel(\"um\")\n",
    "    #plots[3] = Firing_Rate_Layout(sd);\n",
    "    \n",
    "    \n",
    "    # Plot Raster with plotted firing rate over time subplot\n",
    "    # Zoomed Raster and pop rate\n",
    "    # Get coordinates for raster\n",
    "    idces, times = sd.idces_times()\n",
    "    \n",
    "    # Get population rate for everything\n",
    "    pop_rate = sd.binned(bin_size=1)# in ms\n",
    "    # Lets smooth this to make it neater\n",
    "    sigma = 5\n",
    "    pop_rate_smooth = gaussian_filter1d(pop_rate.astype(float),sigma=sigma) \n",
    "    t = np.linspace(0,sd.length,pop_rate.shape[0])/1000\n",
    "    \n",
    "    plots[1,1].scatter(times/1000,idces,marker='|',s=1)\n",
    "    plots2 = plots[1,1].twinx()\n",
    "    plots2.plot(t,pop_rate_smooth,c='r')\n",
    "\n",
    "    plots[1,1].set_xlim(0,seconds)\n",
    "    plots[1,1].set_title(\"Spike Raster Analysis\")\n",
    "    plots[1,1].set_xlabel(\"Time(s)\")\n",
    "    plots[1,1].set_ylabel(\"Unit #\")\n",
    "    plots2.set_ylabel(\"Firing Rate\")\n",
    "    \n",
    "    # Plot second figure ------------------------------------------------------------------\n",
    "    figs2, axs = plt.subplots(nrows=2,ncols=4,figsize=(30,10)) \n",
    "    figs2.suptitle(f\"Interspike Interval of Individual Neural Units of File {filename}\")\n",
    "    \n",
    "    for i in range(8): # Plot individual ISI figures\n",
    "        if(i < sd.N):\n",
    "            if i < 4: # First Row\n",
    "                axs[0,i].hist(IndivISI(sd, i))\n",
    "                axs[0,i].set_title(f\"Interspike Interval of Neural Unit {i}\")\n",
    "                axs[0,i].set_xlabel(\"Time bin(ms)\")\n",
    "                axs[0,i].set_ylabel(\"ISI count\")\n",
    "            else: # Second Row\n",
    "                axs[1,i-4].hist(IndivISI(sd, i))\n",
    "                axs[1,i-4].set_title(f\"Interspike Interval of Neural Unit {i}\")\n",
    "                axs[1,i-4].set_xlabel(\"Time bin(ms)\")\n",
    "                axs[1,i-4].set_ylabel(\"ISI count\")\n",
    "        else: # Print warning title in case neuron count is uner 8\n",
    "            figs2.suptitle(f\"Interspike Interval of Individual Neural Units of File {filename}\\n Note: Neuron Count Under 8 ({sd.N})\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a829e7a",
   "metadata": {},
   "source": [
    "# Deeper Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6494d1",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "## <Font color='grey'>Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e554eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(sd):\n",
    "    # Correlation\n",
    "    corr = np.zeros((sd.N,sd.N)) #inds by inds\n",
    "    \n",
    "    dense_raster = sd.raster(bin_size=1) # in ms\n",
    "    sigma = 5                            # Blur it\n",
    "    dense_raster = gaussian_filter1d(dense_raster.astype(float),sigma=sigma)\n",
    "    corr=np.corrcoef( dense_raster )\n",
    "        \n",
    "    return corr;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b405b1c",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c83a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeeperAnalysis(filename):\n",
    "    # Plots three plots for Spikedata analysis, STTC and Correlation matrices along with Functional Connectivity Map\n",
    "    # set up\n",
    "    sd = read_phy_files(filename)\n",
    "    STTC = sd.spike_time_tilings()\n",
    "    Corr = correlation(sd)\n",
    "    \n",
    "    # Mosaic Layout\n",
    "    figLayout = \"\"\"AB\"\"\"\n",
    "                    \n",
    "    fig, plots = plt.subplot_mosaic(figLayout, figsize=(12,10))\n",
    "    \n",
    "    # subplot of STTC -----------------------------------------------------\n",
    "    pltA = plots[\"A\"].imshow(STTC)\n",
    "    plots[\"A\"].set_title(\"STTC\")\n",
    "    plots[\"A\"].set_xlabel(\"unit\")\n",
    "    plots[\"A\"].set_ylabel(\"unit\")\n",
    "    \n",
    "    fig.colorbar(pltA, ax=plots[\"A\"], shrink=0.3)\n",
    "    \n",
    "    \n",
    "    # subplot of Correlation ----------------------------------------------\n",
    "    pltB = plots[\"B\"].imshow(Corr)\n",
    "    plots[\"B\"].set_title(\"Correlation\")\n",
    "    plots[\"B\"].set_xlabel(\"unit\")\n",
    "    plots[\"B\"].set_ylabel(\"unit\")\n",
    "    \n",
    "    fig.colorbar(pltB, ax=plots[\"B\"], shrink=0.3)\n",
    "    \n",
    "    #subplot of functional connectivity -----------------------------------\n",
    "    fcm.FCM_Plotter(filename, 0, sd.length/1000, \"Functional Connectivity Map\", saved=\"no\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e943a7-cd14-459f-92ca-e157791162ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5146afb-983c-4747-a4ea-93a8598e991b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd69049-4ec3-46ed-9a25-8d032bfba51f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47752649-66ba-43e0-bcda-df824ba8eeaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`read_phy_files` is the function we use to load data. The funciton currently (9/12/23) causes an error on braingeneers, so we use an older version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "from typing import List, Tuple\n",
    "\n",
    "def read_phy_files(path: str, fs=20000.0):\n",
    "    \"\"\"\n",
    "    :param path: a s3 or local path to a zip of phy files.\n",
    "    :return: SpikeData class with a list of spike time lists and neuron_data.\n",
    "            neuron_data = {0: neuron_dict, 1: config_dict}\n",
    "            neuron_dict = {\"new_cluster_id\": {\"channel\": c, \"position\": (x, y),\n",
    "                            \"amplitudes\": [a0, a1, an], \"template\": [t0, t1, tn],\n",
    "                            \"neighbor_channels\": [c0, c1, cn],\n",
    "                            \"neighbor_positions\": [(x0, y0), (x1, y1), (xn,yn)],\n",
    "                            \"neighbor_templates\": [[t00, t01, t0n], [tn0, tn1, tnn]}}\n",
    "            config_dict = {chn: pos}\n",
    "    \"\"\"\n",
    "    assert path[-3:] == 'zip', 'Only zip files supported!'\n",
    "    import braingeneers.utils.smart_open_braingeneers as smart_open\n",
    "    with smart_open.open(path, 'rb') as f0:\n",
    "        f = io.BytesIO(f0.read())\n",
    "\n",
    "        with zipfile.ZipFile(f, 'r') as f_zip:\n",
    "            assert 'params.py' in f_zip.namelist(), \"Wrong spike sorting output.\"\n",
    "            with io.TextIOWrapper(f_zip.open('params.py'), encoding='utf-8') as params:\n",
    "                for line in params:\n",
    "                    if \"sample_rate\" in line:\n",
    "                        fs = float(line.split()[-1])\n",
    "            clusters = np.load(f_zip.open('spike_clusters.npy')).squeeze()\n",
    "            templates = np.load(f_zip.open('templates.npy'))  # (cluster_id, samples, channel_id)\n",
    "            channels = np.load(f_zip.open('channel_map.npy')).squeeze()\n",
    "            templates_w = np.load(f_zip.open('templates.npy'))\n",
    "            wmi = np.load(f_zip.open('whitening_mat_inv.npy'))\n",
    "            spike_templates = np.load(f_zip.open('spike_templates.npy')).squeeze()\n",
    "            spike_times = np.load(f_zip.open('spike_times.npy')).squeeze() / fs * 1e3  # in ms\n",
    "            positions = np.load(f_zip.open('channel_positions.npy'))\n",
    "            amplitudes = np.load(f_zip.open(\"amplitudes.npy\")).squeeze()\n",
    "            if 'cluster_info.tsv' in f_zip.namelist():\n",
    "                cluster_info = pd.read_csv(f_zip.open('cluster_info.tsv'), sep='\\t')\n",
    "                cluster_id = np.array(cluster_info['cluster_id'])\n",
    "                # select clusters using curation label, remove units labeled as \"noise\"\n",
    "                # find the best channel by amplitude\n",
    "                labeled_clusters = cluster_id[cluster_info['group'] != \"noise\"]\n",
    "            else:\n",
    "                labeled_clusters = np.unique(clusters)\n",
    "\n",
    "    df = pd.DataFrame({\"clusters\": clusters, \"spikeTimes\": spike_times, \"amplitudes\": amplitudes})\n",
    "    cluster_agg = df.groupby(\"clusters\").agg({\"spikeTimes\": lambda x: list(x),\n",
    "                                              \"amplitudes\": lambda x: list(x)})\n",
    "    cluster_agg = cluster_agg[cluster_agg.index.isin(labeled_clusters)]\n",
    "\n",
    "    cls_temp = dict(zip(clusters, spike_templates))\n",
    "    neuron_dict = dict.fromkeys(np.arange(len(labeled_clusters)), None)\n",
    "\n",
    "    # un-whitten the templates before finding the best channel\n",
    "    templates = np.dot(templates_w, wmi)\n",
    "\n",
    "    neuron_attributes = []\n",
    "    for i in range(len(labeled_clusters)):\n",
    "        c = labeled_clusters[i]\n",
    "        temp = templates[cls_temp[c]]\n",
    "        amp = np.max(temp, axis=0) - np.min(temp, axis=0)\n",
    "        sorted_idx = [ind for _, ind in sorted(zip(amp, np.arange(len(amp))))]\n",
    "        nbgh_chan_idx = sorted_idx[::-1][:12]\n",
    "        nbgh_temps = temp.transpose()[nbgh_chan_idx]\n",
    "        best_chan_temp = nbgh_temps[0]\n",
    "        nbgh_channels = channels[nbgh_chan_idx]\n",
    "        nbgh_postions = [tuple(positions[idx]) for idx in nbgh_chan_idx]\n",
    "        best_channel = nbgh_channels[0]\n",
    "        best_position = nbgh_postions[0]\n",
    "        # neighbor_templates = dict(zip(nbgh_postions, nbgh_temps))\n",
    "        cls_amp = cluster_agg[\"amplitudes\"][c]\n",
    "        neuron_dict[i] = {\"cluster_id\": c, \"channel\": best_channel, \"position\": best_position,\n",
    "                          \"amplitudes\": cls_amp, \"template\": best_chan_temp,\n",
    "                          \"neighbor_channels\": nbgh_channels, \"neighbor_positions\": nbgh_postions,\n",
    "                          \"neighbor_templates\": nbgh_temps}\n",
    "        neuron_attributes.append(\n",
    "            NeuronAttributes(\n",
    "                cluster_id=c,\n",
    "                channel=best_channel,\n",
    "                position=best_position,\n",
    "                amplitudes=cluster_agg[\"amplitudes\"][c],\n",
    "                template=best_chan_temp,\n",
    "                templates=templates[cls_temp[c]].T,\n",
    "                label=cluster_info['group'][cluster_info['cluster_id'] == c].values[0],\n",
    "                neighbor_channels=channels[nbgh_chan_idx],\n",
    "                neighbor_positions=[tuple(positions[idx]) for idx in nbgh_chan_idx],\n",
    "                neighbor_templates=[templates[cls_temp[c]].T[n] for n in nbgh_chan_idx]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    config_dict = dict(zip(channels, positions))\n",
    "    neuron_data = {0: neuron_dict}\n",
    "    metadata = {0: config_dict}\n",
    "    spikedata = SpikeData(list(cluster_agg[\"spikeTimes\"]), neuron_data=neuron_data, metadata=metadata, neuron_attributes=neuron_attributes)\n",
    "    return spikedata\n",
    "\n",
    "class NeuronAttributes:\n",
    "    cluster_id: int\n",
    "    channel: np.ndarray\n",
    "    position: Tuple[float, float]\n",
    "    amplitudes: List[float]\n",
    "    template: np.ndarray\n",
    "    templates: np.ndarray\n",
    "    label: str\n",
    "\n",
    "    # These lists are the same length and correspond to each other\n",
    "    neighbor_channels: np.ndarray\n",
    "    neighbor_positions: List[Tuple[float, float]]\n",
    "    neighbor_templates: List[np.ndarray]\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.cluster_id = kwargs.pop(\"cluster_id\")\n",
    "        self.channel = kwargs.pop(\"channel\")\n",
    "        self.position = kwargs.pop(\"position\")\n",
    "        self.amplitudes = kwargs.pop(\"amplitudes\")\n",
    "        self.template = kwargs.pop(\"template\")\n",
    "        self.templates = kwargs.pop(\"templates\")\n",
    "        self.label = kwargs.pop(\"label\")\n",
    "        self.neighbor_channels = kwargs.pop(\"neighbor_channels\")\n",
    "        self.neighbor_positions = kwargs.pop(\"neighbor_positions\")\n",
    "        self.neighbor_templates = kwargs.pop(\"neighbor_templates\")\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def add_attribute(self, key, value):\n",
    "        setattr(self, key, value)\n",
    "\n",
    "    def list_attributes(self):\n",
    "        return [attr for attr in dir(self) if not attr.startswith('__') and not callable(getattr(self, attr))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371d9571",
   "metadata": {},
   "source": [
    "## <font color='brown'>test main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5d35242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = '/home/jovyan/data/ephys/2023-05-09-e-hc52_18763/derived/kilosort2/hc52_18763_rec05092023_12_curated.zip'\n",
    "#sd = read_phy_files(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0816d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fcm.FCM_Plotter(file, 0, sd.length/1000, \"plot\", saved=\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ad19745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interact_manual( DeeperAnalysis, filename=filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9ba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\tDone!\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
