{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# Data analysis packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import correlate, correlation_lags\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Visualization packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import FancyArrow, Patch, Circle\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Image processing packages\n",
    "import imageio\n",
    "from PIL import Image, ImageSequence\n",
    "\n",
    "# Braingeneers packages for analysis\n",
    "import braingeneers\n",
    "import braingeneers.data.datasets_electrophysiology as ephys\n",
    "from braingeneers.analysis.analysis import SpikeData, read_phy_files, load_spike_data, burst_detection, randomize_raster\n",
    "\n",
    "import diptest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/workspaces/human_hippocampus/dev/other/thomas/thesis/pickled_datasets/random_dataset.pkl', 'rb') as file:\n",
    "#     sd = pickle.load(file)\n",
    "\n",
    "with open('/workspaces/human_hippocampus/data/ephys/2023-04-02-e-hc328_unperturbed/sd_ca1_curated.pkl', \"rb\") as my_file:\n",
    "    sd = pickle.load(my_file)\n",
    "\n",
    "# with open('/workspaces/human_hippocampus/data/processed/ephys/2023-12-03-e-Hc112823_avv9hckcr1/curated_base_acqm.pkl', 'rb') as file:\n",
    "#     sd = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional Connectivity Map Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "dT = 20\n",
    "MIN_SPIKES = 5\n",
    "MIN_COEF_THRESH = 0.1\n",
    "MEAN_THRESH = 2\n",
    "PVAL_THRESH = 0.1\n",
    "FWHM_THRESH = 15\n",
    "NBOOT = 500\n",
    "DIRECTIONAL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize result matrices\n",
    "N = sd.N\n",
    "tile_coefficients_whole = np.nan * np.zeros((N, N))\n",
    "mean_latencies = np.nan * np.zeros((N, N))\n",
    "pvals_per_edge = np.nan * np.zeros((N, N))\n",
    "fwhm_per_edge = np.nan * np.zeros((N, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_latencies(ref_spike_times, comp_spike_times):\n",
    "    # Initialize empty list to store results\n",
    "    latencies = []\n",
    "\n",
    "    # Iterate through each spike time in the reference list\n",
    "    for ref_time_idx, ref_time in enumerate(ref_spike_times):\n",
    "        \n",
    "        # Find the spike in the comparison list that lies closest to the current reference spike\n",
    "        time_differences = np.abs(comp_spike_times - ref_time)\n",
    "        min_diff = np.min(time_differences)\n",
    "        closest_comp = comp_spike_times[np.where(time_differences == min_diff)[0][0]]\n",
    "        \n",
    "        # Calculate the time difference\n",
    "        time_diff = closest_comp - ref_time\n",
    "\n",
    "        # If the time difference is positive\n",
    "        if time_diff > 0:\n",
    "            # Check if the next reference spike is closer than the closest comparison spike\n",
    "            if ref_time_idx == len(ref_spike_times) - 1 or ref_spike_times[ref_time_idx + 1] - ref_time > time_diff:\n",
    "                # Store the result\n",
    "                latencies.append(time_diff)\n",
    "        \n",
    "        # If the time difference is negative\n",
    "        elif time_diff < 0:\n",
    "            # Check if the previous reference spike is closer than the closest comparison spike\n",
    "            if ref_time_idx == 0 or ref_spike_times[ref_time_idx - 1] - ref_time < time_diff:\n",
    "                # Store the result\n",
    "                latencies.append(time_diff)\n",
    "                \n",
    "    return np.array(latencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HartigansDipSignifTest(data):\n",
    "    # Calculate dip statistic\n",
    "    dip, p_value = diptest.diptest(data)\n",
    "    \n",
    "    return dip, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES2\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES2\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES\n",
      "YES2\n",
      "YES\n",
      "YES2\n",
      "YES\n",
      "YES2\n",
      "YES\n",
      "YES\n"
     ]
    }
   ],
   "source": [
    "sttc_values = sd.spike_time_tilings(delt=dT)\n",
    "\n",
    "for ref_channel in range(N):\n",
    "    for comp_channel in range(N):\n",
    "        if comp_channel == ref_channel:\n",
    "            continue\n",
    "        # Get the spike times for the reference and comparison channels\n",
    "        ref_spikes = sd.train[ref_channel]\n",
    "        comp_spikes = sd.train[comp_channel]\n",
    "\n",
    "        # Ensure both channels have a minimum number of spikes\n",
    "        if len(ref_spikes) >= MIN_SPIKES and len(comp_spikes) >= MIN_SPIKES:\n",
    "            # Calculate STTC\n",
    "            sttc_val = sttc_values[ref_channel, comp_channel]\n",
    "            # print(\"Ref, Comp, STTC: \", ref_channel, comp_channel, sttc_val)\n",
    "\n",
    "            if sttc_val > MIN_COEF_THRESH:\n",
    "                # Extract latencies\n",
    "                latencies = extract_latencies(ref_spikes, comp_spikes)\n",
    "\n",
    "                # Remove latencies larger than dT\n",
    "                latencies = latencies[np.abs(latencies) < dT]\n",
    "\n",
    "                if np.abs(np.mean(latencies)) > MEAN_THRESH:\n",
    "                    \n",
    "                    pdf = np.sort(latencies)\n",
    "                    # Perform Hartigan's dip test for multimodality\n",
    "                    dip, p_value = HartigansDipSignifTest(pdf)\n",
    "\n",
    "                    if p_value > PVAL_THRESH:\n",
    "                        print(\"YES\")\n",
    "                        # Compute FWHM assuming normal distribution of latencies\n",
    "                        pd_mean, pd_std = norm.fit(latencies)\n",
    "                        fwhm = 2 * np.sqrt(2 * np.log(2)) * pd_std\n",
    "\n",
    "                        if fwhm < FWHM_THRESH:\n",
    "                            print(\"YES2\")\n",
    "                            # Store results\n",
    "                            mean_latencies[comp_channel, ref_channel] = np.mean(latencies)\n",
    "                            pvals_per_edge[comp_channel, ref_channel] = p_value\n",
    "                            fwhm_per_edge[comp_channel, ref_channel] = fwhm\n",
    "\n",
    "                            if DIRECTIONAL:\n",
    "                                # Adjust storage basen on mean latency direction\n",
    "                                if mean_latencies[comp_channel, ref_channel] > MEAN_THRESH:\n",
    "                                    tile_coefficients_whole[comp_channel, ref_channel] = sttc_val\n",
    "                                elif mean_latencies[comp_channel, ref_channel] < -MEAN_THRESH:\n",
    "                                    tile_coefficients_whole[comp_channel, ref_channel] = sttc_val\n",
    "                            else:\n",
    "                                if np.abs(mean_latencies[comp_channel, ref_channel]) > MEAN_THRESH:\n",
    "                                    tile_coefficients_whole[comp_channel, ref_channel] = sttc_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number non nan\n",
    "np.sum(~np.isnan(tile_coefficients_whole))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get neuron positions\n",
    "def get_neuron_positions(spike_data):\n",
    "    # Extract neuron positions from spike_data\n",
    "    neuron_x = []\n",
    "    neuron_y = []\n",
    "    for neuron in spike_data.neuron_data['positions'].values():\n",
    "        neuron_x.append(neuron['position'][0])\n",
    "        neuron_y.append(neuron['position'][1])\n",
    "    neuron_positions = np.array([neuron_x, neuron_y]).T\n",
    "    return neuron_positions\n",
    "\n",
    "def calculate_mean_firing_rates(spike_data):\n",
    "    mean_firing_rates = []\n",
    "    for neuron_spikes in spike_data.train:\n",
    "        num_spikes = len(neuron_spikes)\n",
    "        time_duration = spike_data.length / 1000  # Assuming spike times are in milliseconds\n",
    "        firing_rate = num_spikes / time_duration\n",
    "        mean_firing_rates.append(firing_rate)\n",
    "\n",
    "    return np.array(mean_firing_rates)\n",
    "\n",
    "def latencies_mean_neuron(lat_list):\n",
    "    \"\"\"\n",
    "    Output: Returns a list containing the mean latencies for each sublist.\n",
    "    Input: lat_list- A list of lists representing latencies between a particular neuron, x, and all others. Created with `sd.latencies_to_index(x)`\n",
    "    \"\"\"\n",
    "    nested_list = lat_list\n",
    "    for i in range(len(nested_list)):\n",
    "        sublist = nested_list[i]\n",
    "        length = len(sublist)\n",
    "        if length == 0:\n",
    "            sublist_mean = 0\n",
    "        else:\n",
    "            sublist_mean = sum(sublist)/len(sublist)\n",
    "            sublist_mean = round(sublist_mean, 3) # Round to 3d.p.\n",
    "        nested_list[i] = sublist_mean\n",
    "    return nested_list\n",
    "\n",
    "def latencies_mean_all(sd):\n",
    "    \"\"\"\n",
    "    Output: Returns a list of lists containing the mean latencies between all neurons\n",
    "    Input: sd- A SpikeData object, the standard data format for braingeneers\n",
    "    \"\"\"\n",
    "    latencies_array = [None] * sd.N\n",
    "    for curr_neuron in range(sd.N):\n",
    "        latencies = latencies_mean_neuron(sd.latencies_to_index(curr_neuron))\n",
    "        latencies_array[curr_neuron] = latencies # Store mean latency in corresponding position of 'latencies_array2'\n",
    "    return latencies_array\n",
    "\n",
    "def get_in_out_degree( mean_latency_matrix ): \n",
    "    \"\"\"\n",
    "    Output: Returns a list of tuples, [(incoming,outgoing),....] , containing the in and out degree for each neuron. \n",
    "            This is the number of \"receicer\" and \"sender\" signals the neurons get from other neurons\n",
    "    Input: mean_latency_matrix- A list of lists containing the mean latency between all neurons\n",
    "    \"\"\"\n",
    "    in_out_deg = [(0, 0) for _ in range(len(mean_latency_matrix))]\n",
    "    for curr_neuron in range(len(mean_latency_matrix)):\n",
    "        in_deg = 0\n",
    "        out_deg = 0\n",
    "        curr_neural_latencies = mean_latency_matrix[curr_neuron]\n",
    "        for i in range(len(curr_neural_latencies)):\n",
    "            if curr_neural_latencies[i] > 0:\n",
    "                out_deg += 1\n",
    "            if curr_neural_latencies[i] < 0:\n",
    "                in_deg += 1\n",
    "        in_out_deg[curr_neuron] = (in_deg, out_deg)\n",
    "    return in_out_deg\n",
    "\n",
    "def label_sender_receiver_neurons(in_out_deg, latency_thresh=0.2):\n",
    "    node_info = ['grey'] * len(in_out_deg)\n",
    "    for i in range(len(in_out_deg)):\n",
    "        if (in_out_deg[i][1] + in_out_deg[i][0]) == 0:\n",
    "            test1 = 0\n",
    "            test2 = 0\n",
    "        else:\n",
    "            test1 = (in_out_deg[i][1] - in_out_deg[i][0]) / (in_out_deg[i][1] + in_out_deg[i][0])\n",
    "            test2 = (in_out_deg[i][0] - in_out_deg[i][1]) / (in_out_deg[i][1] + in_out_deg[i][0])\n",
    "        \n",
    "        if test1 > latency_thresh:\n",
    "            node_info[i] = 'red'\n",
    "        elif test2 > latency_thresh:\n",
    "            node_info[i] = 'blue'\n",
    "    return node_info\n",
    "\n",
    "def plot_functional_connectivity_map( sd, latency_threshold=.1, show_sttc=True,  sttc_threshold=.1):\n",
    "    \"\"\"\n",
    "    Output: plots the functional connectivity map, displayin \"sender\" and \"\"receiver\" neurons in the neural circuit\n",
    "    Inputs:\n",
    "        sd (SpikeData object)- the standard data format for braingeneers\n",
    "        latency_threshold (float)- Between 0-1. The threshold for the fraction of in/out signals a neuron must have to be labelled a \"sender\" or \"receiver\"\n",
    "        show_sttc (boolean)- If True, the spike time tiling connections between neurons are also plotted\n",
    "        sttc_threshold (float)- Between 0-1. The strength a spike time tiling correlation must be above in order to be plotted\n",
    "    \"\"\"\n",
    "    # Plot functional connectivity map\n",
    "    print(\"calculating all latencies...\")\n",
    "    all_mean_latencies = latencies_mean_all(sd)\n",
    "    in_out_deg = get_in_out_degree(all_mean_latencies)\n",
    "    sender_receiver_neurons = label_sender_receiver_neurons(in_out_deg, latency_threshold )\n",
    "    print(\"making plot\")\n",
    "    neuron_x = []\n",
    "    neuron_y = []\n",
    "    for neuron in sd.neuron_data['positions'].values():\n",
    "        neuron_x.append(neuron['position'][0])\n",
    "        neuron_y.append(neuron['position'][1])\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.scatter(neuron_x, neuron_y, c=sender_receiver_neurons)\n",
    "    # Plot legend for functional connectivity map\n",
    "    node_type_legend_elements = [\n",
    "    plt.scatter([], [], s=50, marker='o', edgecolor='black', facecolor='grey', label='Broker'),\n",
    "    plt.scatter([], [], s=50, marker='o', edgecolor='black', facecolor='red', label='Sender'),\n",
    "    plt.scatter([], [], s=50, marker='o', edgecolor='black', facecolor='blue', label='Receiver')\n",
    "    ]\n",
    "    node_type_legend = plt.legend(handles=node_type_legend_elements, title='Node Type', loc='best')\n",
    "    plt.gca().add_artist(node_type_legend)\n",
    "    plt.title(\"Functional Connectivity Map - Random Data\")\n",
    "    plt.xlabel('X position')\n",
    "    plt.ylabel('Y position')\n",
    "\n",
    "    # Plot spike time tiling connections between neurons\n",
    "    if show_sttc:\n",
    "        sttc = sd.spike_time_tilings(delt=40)\n",
    "        for i in range(sttc.shape[0]):\n",
    "            for j in range(sttc.shape[1]):\n",
    "                if i <= j: continue\n",
    "                if sttc[i,j] < sttc_threshold : continue\n",
    "                ix,iy = sd.neuron_data['positions'][i]['position']\n",
    "                jx,jy = sd.neuron_data['positions'][j]['position']\n",
    "                # ix,iy = sd.neuron_data[0][i]['position']\n",
    "                # jx,jy = sd.neuron_data[0][j]['position']\n",
    "                linewidth = 1.5 + 2 * (sttc[i, j] - sttc_threshold)\n",
    "                opacity = 0.2 + 0.8 * (sttc[i, j] - sttc_threshold)  # Modify opacity based on correlation\n",
    "                # Plot line between the points with linewidth and opacity\n",
    "                plt.plot([ix, jx], [iy, jy], linewidth=linewidth, c='grey', alpha=opacity)\n",
    "        # Create legend for spike time tilings\n",
    "        correlation_legend_elements = [\n",
    "            plt.Line2D([0], [0], color='grey', linewidth=0.5, label='0.6'),\n",
    "            plt.Line2D([0], [0], color='grey', linewidth=1.0, label='0.8'),\n",
    "            plt.Line2D([0], [0], color='grey', linewidth=1.5, label='1.0')\n",
    "        ]\n",
    "        correlation_legend = plt.legend(handles=correlation_legend_elements, title='Correlation', loc='lower left')\n",
    "        plt.gca().add_artist(correlation_legend)\n",
    "    \n",
    "    # Invert y axis to match the image\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    # Make x and y axis equal\n",
    "    plt.axis('equal')\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
