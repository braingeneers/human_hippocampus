{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=7> Read Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code to read phy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import fcm\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "import scipy.ndimage as ndimage\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Patch, Circle\n",
    "from matplotlib.lines import Line2D\n",
    "from PIL import Image\n",
    "import ipywidgets as ipw\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual  # package for interactive widgets \n",
    "import braingeneers                                                   # Braingeneers code\n",
    "from braingeneers.analysis.analysis import SpikeData, read_phy_files\n",
    "import braingeneers.data.datasets_electrophysiology as ephys\n",
    "from IPython.display import HTML, display, Javascript, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "from typing import List, Tuple\n",
    "\n",
    "def read_phy_files(path: str, fs=20000.0):\n",
    "    \"\"\"\n",
    "    :param path: a s3 or local path to a zip of phy files.\n",
    "    :return: SpikeData class with a list of spike time lists and neuron_data.\n",
    "            neuron_data = {0: neuron_dict, 1: config_dict}\n",
    "            neuron_dict = {\"new_cluster_id\": {\"channel\": c, \"position\": (x, y),\n",
    "                            \"amplitudes\": [a0, a1, an], \"template\": [t0, t1, tn],\n",
    "                            \"neighbor_channels\": [c0, c1, cn],\n",
    "                            \"neighbor_positions\": [(x0, y0), (x1, y1), (xn,yn)],\n",
    "                            \"neighbor_templates\": [[t00, t01, t0n], [tn0, tn1, tnn]}}\n",
    "            config_dict = {chn: pos}\n",
    "    \"\"\"\n",
    "    assert path[-3:] == 'zip', 'Only zip files supported!'\n",
    "    import braingeneers.utils.smart_open_braingeneers as smart_open\n",
    "    with smart_open.open(path, 'rb') as f0:\n",
    "        f = io.BytesIO(f0.read())\n",
    "\n",
    "        with zipfile.ZipFile(f, 'r') as f_zip:\n",
    "            assert 'params.py' in f_zip.namelist(), \"Wrong spike sorting output.\"\n",
    "            with io.TextIOWrapper(f_zip.open('params.py'), encoding='utf-8') as params:\n",
    "                for line in params:\n",
    "                    if \"sample_rate\" in line:\n",
    "                        fs = float(line.split()[-1])\n",
    "            clusters = np.load(f_zip.open('spike_clusters.npy')).squeeze()\n",
    "            templates = np.load(f_zip.open('templates.npy'))  # (cluster_id, samples, channel_id)\n",
    "            channels = np.load(f_zip.open('channel_map.npy')).squeeze()\n",
    "            templates_w = np.load(f_zip.open('templates.npy'))\n",
    "            wmi = np.load(f_zip.open('whitening_mat_inv.npy'))\n",
    "            spike_templates = np.load(f_zip.open('spike_templates.npy')).squeeze()\n",
    "            spike_times = np.load(f_zip.open('spike_times.npy')).squeeze() / fs * 1e3  # in ms\n",
    "            positions = np.load(f_zip.open('channel_positions.npy'))\n",
    "            amplitudes = np.load(f_zip.open(\"amplitudes.npy\")).squeeze()\n",
    "            if 'cluster_info.tsv' in f_zip.namelist():\n",
    "                cluster_info = pd.read_csv(f_zip.open('cluster_info.tsv'), sep='\\t')\n",
    "                cluster_id = np.array(cluster_info['cluster_id'])\n",
    "                # select clusters using curation label, remove units labeled as \"noise\"\n",
    "                # find the best channel by amplitude\n",
    "                labeled_clusters = cluster_id[cluster_info['group'] != \"noise\"]\n",
    "            else:\n",
    "                labeled_clusters = np.unique(clusters)\n",
    "\n",
    "    df = pd.DataFrame({\"clusters\": clusters, \"spikeTimes\": spike_times, \"amplitudes\": amplitudes})\n",
    "    cluster_agg = df.groupby(\"clusters\").agg({\"spikeTimes\": lambda x: list(x),\n",
    "                                              \"amplitudes\": lambda x: list(x)})\n",
    "    cluster_agg = cluster_agg[cluster_agg.index.isin(labeled_clusters)]\n",
    "\n",
    "    cls_temp = dict(zip(clusters, spike_templates))\n",
    "    neuron_dict = dict.fromkeys(np.arange(len(labeled_clusters)), None)\n",
    "\n",
    "    # un-whitten the templates before finding the best channel\n",
    "    templates = np.dot(templates_w, wmi)\n",
    "\n",
    "    neuron_attributes = []\n",
    "    for i in range(len(labeled_clusters)):\n",
    "        c = labeled_clusters[i]\n",
    "        temp = templates[cls_temp[c]]\n",
    "        amp = np.max(temp, axis=0) - np.min(temp, axis=0)\n",
    "        sorted_idx = [ind for _, ind in sorted(zip(amp, np.arange(len(amp))))]\n",
    "        nbgh_chan_idx = sorted_idx[::-1][:12]\n",
    "        nbgh_temps = temp.transpose()[nbgh_chan_idx]\n",
    "        best_chan_temp = nbgh_temps[0]\n",
    "        nbgh_channels = channels[nbgh_chan_idx]\n",
    "        nbgh_postions = [tuple(positions[idx]) for idx in nbgh_chan_idx]\n",
    "        best_channel = nbgh_channels[0]\n",
    "        best_position = nbgh_postions[0]\n",
    "        # neighbor_templates = dict(zip(nbgh_postions, nbgh_temps))\n",
    "        cls_amp = cluster_agg[\"amplitudes\"][c]\n",
    "        neuron_dict[i] = {\"cluster_id\": c, \"channel\": best_channel, \"position\": best_position,\n",
    "                          \"amplitudes\": cls_amp, \"template\": best_chan_temp,\n",
    "                          \"neighbor_channels\": nbgh_channels, \"neighbor_positions\": nbgh_postions,\n",
    "                          \"neighbor_templates\": nbgh_temps}\n",
    "        neuron_attributes.append(\n",
    "            NeuronAttributes(\n",
    "                cluster_id=c,\n",
    "                channel=best_channel,\n",
    "                position=best_position,\n",
    "                amplitudes=cluster_agg[\"amplitudes\"][c],\n",
    "                template=best_chan_temp,\n",
    "                templates=templates[cls_temp[c]].T,\n",
    "                label=cluster_info['group'][cluster_info['cluster_id'] == c].values[0],\n",
    "                neighbor_channels=channels[nbgh_chan_idx],\n",
    "                neighbor_positions=[tuple(positions[idx]) for idx in nbgh_chan_idx],\n",
    "                neighbor_templates=[templates[cls_temp[c]].T[n] for n in nbgh_chan_idx]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    config_dict = dict(zip(channels, positions))\n",
    "    neuron_data = {0: neuron_dict}\n",
    "    metadata = {0: config_dict}\n",
    "    spikedata = SpikeData(list(cluster_agg[\"spikeTimes\"]), neuron_data=neuron_data, metadata=metadata, neuron_attributes=neuron_attributes)\n",
    "    return spikedata\n",
    "\n",
    "class NeuronAttributes:\n",
    "    cluster_id: int\n",
    "    channel: np.ndarray\n",
    "    position: Tuple[float, float]\n",
    "    amplitudes: List[float]\n",
    "    template: np.ndarray\n",
    "    templates: np.ndarray\n",
    "    label: str\n",
    "\n",
    "    # These lists are the same length and correspond to each other\n",
    "    neighbor_channels: np.ndarray\n",
    "    neighbor_positions: List[Tuple[float, float]]\n",
    "    neighbor_templates: List[np.ndarray]\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.cluster_id = kwargs.pop(\"cluster_id\")\n",
    "        self.channel = kwargs.pop(\"channel\")\n",
    "        self.position = kwargs.pop(\"position\")\n",
    "        self.amplitudes = kwargs.pop(\"amplitudes\")\n",
    "        self.template = kwargs.pop(\"template\")\n",
    "        self.templates = kwargs.pop(\"templates\")\n",
    "        self.label = kwargs.pop(\"label\")\n",
    "        self.neighbor_channels = kwargs.pop(\"neighbor_channels\")\n",
    "        self.neighbor_positions = kwargs.pop(\"neighbor_positions\")\n",
    "        self.neighbor_templates = kwargs.pop(\"neighbor_templates\")\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def add_attribute(self, key, value):\n",
    "        setattr(self, key, value)\n",
    "\n",
    "    def list_attributes(self):\n",
    "        return [attr for attr in dir(self) if not attr.startswith('__') and not callable(getattr(self, attr))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
